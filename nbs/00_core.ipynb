{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# core\n",
    "\n",
    "> Fetching transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp core "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import os\n",
    "import re\n",
    "from pathlib import Path\n",
    "from fastcore.all import *\n",
    "from tqdm import tqdm   \n",
    "import subprocess\n",
    "import logging\n",
    "from rich import print\n",
    "\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "import asyncio\n",
    "\n",
    "import ffmpeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "gemini_api_key = os.getenv(\"GEMINI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "logging.basicConfig(level=logging.INFO, \n",
    "                    format='%(asctime)s - %(levelname)s - %(message)s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "def download_audio(\n",
    "    vid_id: str, # YouTube video ID\n",
    "    dest_dir: Path # Output directory\n",
    "    ):\n",
    "    \"Download audio from YouTube video\"\n",
    "    logging.info(f\"Downloading audio for video {vid_id}\")\n",
    "    Path(dest_dir).mkdir(exist_ok=True)\n",
    "    out_file = Path(dest_dir)/f'{vid_id}.mp3'\n",
    "    if not out_file.exists():\n",
    "        subprocess.run(['yt-dlp', '-x', '--audio-format', 'mp3', f'https://www.youtube.com/watch?v={vid_id}', '-o', str(out_file)], check=True)\n",
    "        logging.info(f\"Downloaded audio to {out_file}\")\n",
    "    else:\n",
    "        logging.info(f\"Using existing audio file {out_file}\")\n",
    "    return out_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-20 19:09:25,533 - INFO - Downloading audio for video GJ0u09SIPh4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[youtube] Extracting URL: https://www.youtube.com/watch?v=GJ0u09SIPh4\n",
      "[youtube] GJ0u09SIPh4: Downloading webpage\n",
      "[youtube] GJ0u09SIPh4: Downloading tv client config\n",
      "[youtube] GJ0u09SIPh4: Downloading player 69b31e11-main\n",
      "[youtube] GJ0u09SIPh4: Downloading tv player API JSON\n",
      "[youtube] GJ0u09SIPh4: Downloading ios player API JSON\n",
      "[youtube] GJ0u09SIPh4: Downloading m3u8 information\n",
      "[info] GJ0u09SIPh4: Downloading 1 format(s): 251\n",
      "[download] Destination: ../_audio/GJ0u09SIPh4.webm\n",
      "[download] 100% of   83.98MiB in 00:00:08 at 9.79MiB/s     \n",
      "[ExtractAudio] Destination: ../_audio/GJ0u09SIPh4.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-20 19:10:17,770 - INFO - Downloaded audio to ../_audio/GJ0u09SIPh4.mp3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting original file ../_audio/GJ0u09SIPh4.webm (pass -k to keep)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Path('../_audio/GJ0u09SIPh4.mp3')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: False\n",
    "video_id = 'GJ0u09SIPh4'\n",
    "download_audio(video_id, Path('../_audio'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "def detect_silence(audio_file:Path):\n",
    "    \"Detect silence in audio file and return start and end times\"\n",
    "    stream = ffmpeg.input(str(audio_file))\n",
    "    stream = stream.filter('silencedetect', noise='-30dB', d=0.5)\n",
    "    stream = stream.output('null', f='null')\n",
    "    out, err = ffmpeg.run(stream, capture_stderr=True)\n",
    "    return out, err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: False\n",
    "_, err = detect_silence(Path('../_audio/GJ0u09SIPh4.mp3'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "def parse_silence_ends(stderr_output:bytes):\n",
    "    \"Parse silence ends from ffmpeg stderr output\"\n",
    "    pattern = r'silence_end: ([\\d.]+)'\n",
    "    matches = re.findall(pattern, stderr_output.decode())\n",
    "    return [float(match) for match in matches]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#10) [0.513563,15.558687,26.482021,29.918437,32.245583,34.150583,35.980771,36.597167,39.411437,43.585812]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: False\n",
    "ends = parse_silence_ends(err); L(ends)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "def find_split_points(\n",
    "    silence_ends:list[float], # silence ends\n",
    "    total_len:float, # total length of the audio (in seconds)\n",
    "    chunk_len:float=600 # length of the chunks (in seconds)\n",
    "    ):\n",
    "    \"Find points to split audio based on silence detection, aiming for chunks of `chunk_len` seconds\"\n",
    "    splits,target = [0],chunk_len\n",
    "    for t in silence_ends:\n",
    "        if t >= target:\n",
    "            splits.append(t)\n",
    "            target += chunk_len\n",
    "    splits.append(total_len) # final chunk\n",
    "    return splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "def get_audio_duration(audio_file:\"Path|str\"):\n",
    "    \"Get duration of audio file in seconds\"\n",
    "    probe = ffmpeg.probe(str(audio_file))\n",
    "    return float(probe['format']['duration'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6995.976"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: False\n",
    "tot_len = get_audio_duration(Path('../_audio/GJ0u09SIPh4.mp3')); tot_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 603.482062,\n",
       " 1202.536562,\n",
       " 1802.256479,\n",
       " 2401.709521,\n",
       " 3004.959437,\n",
       " 3605.712229,\n",
       " 4206.138958,\n",
       " 4800.153625,\n",
       " 5400.729625,\n",
       " 6003.723708,\n",
       " 6610.651771,\n",
       " 6995.976]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: False\n",
    "soft_splits = find_split_points(ends, tot_len); soft_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "def get_mime_type(f): return 'audio/mpeg' if Path(f).suffix.lower() == '.mp3' else 'audio/mp4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "def split_audio(\n",
    "    fname:\"Path\", # Audio file to split\n",
    "    splits:\"list\", # List of timestamps in seconds to split at\n",
    "    dest_dir:'str|Path'=\"_audio_chunks\"): # Directory to save chunks\n",
    "    \"Split audio file into chunks based on split points\"\n",
    "    Path(dest_dir).mkdir(exist_ok=True)\n",
    "    chunks = []\n",
    "    for i, start_time in tqdm(enumerate(splits[:-1]), total=len(splits)-1):\n",
    "        duration = splits[i+1] - start_time\n",
    "        chunk_name = f\"{fname.stem}_chunk_{i+1:02d}.mp3\"\n",
    "        output_path = Path(dest_dir)/chunk_name\n",
    "        chunks.append(output_path)\n",
    "        (ffmpeg\n",
    "         .input(str(fname), ss=start_time, t=duration)\n",
    "         .output(str(output_path), acodec='copy')\n",
    "         .overwrite_output()\n",
    "         .run(capture_stdout=True, capture_stderr=True))\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [00:02<00:00,  5.70it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Path('../_audio/_audio_chunks/GJ0u09SIPh4_chunk_01.mp3'),\n",
       " Path('../_audio/_audio_chunks/GJ0u09SIPh4_chunk_02.mp3'),\n",
       " Path('../_audio/_audio_chunks/GJ0u09SIPh4_chunk_03.mp3'),\n",
       " Path('../_audio/_audio_chunks/GJ0u09SIPh4_chunk_04.mp3'),\n",
       " Path('../_audio/_audio_chunks/GJ0u09SIPh4_chunk_05.mp3'),\n",
       " Path('../_audio/_audio_chunks/GJ0u09SIPh4_chunk_06.mp3'),\n",
       " Path('../_audio/_audio_chunks/GJ0u09SIPh4_chunk_07.mp3'),\n",
       " Path('../_audio/_audio_chunks/GJ0u09SIPh4_chunk_08.mp3'),\n",
       " Path('../_audio/_audio_chunks/GJ0u09SIPh4_chunk_09.mp3'),\n",
       " Path('../_audio/_audio_chunks/GJ0u09SIPh4_chunk_10.mp3'),\n",
       " Path('../_audio/_audio_chunks/GJ0u09SIPh4_chunk_11.mp3'),\n",
       " Path('../_audio/_audio_chunks/GJ0u09SIPh4_chunk_12.mp3')]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: False\n",
    "split_audio(Path('../_audio/GJ0u09SIPh4.mp3'), soft_splits, dest_dir='../_audio/_audio_chunks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "async def transcribe_audio(\n",
    "    chunks_dir:str|Path,  # Directory containing audio chunks\n",
    "    dest_file:str|Path, # File to save transcript to\n",
    "    model:str='gemini-2.0-flash-001', # Gemini model to use\n",
    "    max_concurrent:int=3,   # Max concurrent transcriptions\n",
    "    prompt:str=\"Please transcribe this audio file:\" # Custom prompt for transcription\n",
    ") -> str:\n",
    "    \"Transcribe audio chunks in parallel and combine into single transcript\"\n",
    "    semaphore = asyncio.Semaphore(max_concurrent)\n",
    "    client = genai.Client(api_key=os.environ['GEMINI_API_KEY'])\n",
    "    \n",
    "    async def _transcribe_chunk(chunk_path):\n",
    "        async with semaphore:\n",
    "            audio_data = chunk_path.read_bytes()\n",
    "            audio_part = types.Part.from_bytes(\n",
    "                mime_type=get_mime_type(chunk_path), \n",
    "                data=audio_data\n",
    "            )\n",
    "            response = await client.aio.models.generate_content(\n",
    "                model=model,\n",
    "                contents=[prompt, audio_part]\n",
    "            )\n",
    "            return response.text\n",
    "    \n",
    "    chunks = sorted(Path(chunks_dir).glob(\"*.mp3\"))\n",
    "    tasks = [_transcribe_chunk(chunk) for chunk in chunks]\n",
    "    transcripts = await asyncio.gather(*tasks)\n",
    "    \n",
    "    full_transcript = '\\n'.join(transcripts)\n",
    "    dest_path = Path(dest_file)\n",
    "    dest_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    dest_path.write_text(full_transcript)\n",
    "    return full_transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-20 19:21:07,363 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-07-20 19:21:07,403 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-07-20 19:21:07,446 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-07-20 19:21:21,297 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-001:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-07-20 19:21:21,307 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-07-20 19:21:21,745 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-001:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-07-20 19:21:21,758 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-07-20 19:21:22,070 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-001:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-07-20 19:21:22,075 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-07-20 19:21:35,576 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-001:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-07-20 19:21:35,584 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-07-20 19:21:36,409 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-001:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-07-20 19:21:36,418 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-07-20 19:21:37,558 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-001:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-07-20 19:21:37,597 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-07-20 19:21:48,528 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-001:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-07-20 19:21:48,536 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-07-20 19:21:50,344 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-001:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-07-20 19:21:50,352 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-07-20 19:21:51,937 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-001:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-07-20 19:21:51,946 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2025-07-20 19:22:02,123 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-001:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-07-20 19:22:02,547 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-001:generateContent \"HTTP/1.1 200 OK\"\n",
      "2025-07-20 19:22:05,145 - INFO - HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-001:generateContent \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "#| eval: False\n",
    "transcript = await transcribe_audio(\n",
    "    chunks_dir=\"../_audio/_audio_chunks\", \n",
    "    dest_file=\"../_transcripts/transcript.txt\",\n",
    "    prompt=\"Please transcribe this audio file verbatim. Note that this is an academic course in French from College de France. The transcript should be in French.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Bien, mesdames messieurs. Merci d'être venus euh aussi nombreux. Cette affluence est impressionnante. Euh, je salue\n",
       "toutes les personnes aussi qui vont nous suivre sur internet et peut-être sur France Culture, je ne sais pas \n",
       "encore. Et j'espère pouvoir, je vais utiliser des diapositives et pouvoir les mettre euh en ligne et les rendre \n",
       "disponibles en ligne sur le site du du Collège de France. Alors après la leçon inaugurale prononcée le <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span> avril, \n",
       "donc nous entamons aujourd'hui les cours de l'année universitaire, de ce qui reste de l'année universitaire \n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2017</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2018</span>, cette année étant déjà très avancée, les contraintes de salle et de calendrier étant ce qu'elles sont, \n",
       "il n'a pas été possible de programmer ces cours suivant un rythme hebdomadaire régulier et c'est l'année prochaine \n",
       "seulement que nous aurons droit à un créneau fixe à compter du mois de janvier euh sachant toutefois que le \n",
       "séminaire public de l'année prochaine qui va doubler le cours donc commencera en fait dès la fin novembre.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Bien, mesdames messieurs. Merci d'être venus euh aussi nombreux. Cette affluence est impressionnante. Euh, je salue\n",
       "toutes les personnes aussi qui vont nous suivre sur internet et peut-être sur France Culture, je ne sais pas \n",
       "encore. Et j'espère pouvoir, je vais utiliser des diapositives et pouvoir les mettre euh en ligne et les rendre \n",
       "disponibles en ligne sur le site du du Collège de France. Alors après la leçon inaugurale prononcée le \u001b[1;36m5\u001b[0m avril, \n",
       "donc nous entamons aujourd'hui les cours de l'année universitaire, de ce qui reste de l'année universitaire \n",
       "\u001b[1;36m2017\u001b[0m-\u001b[1;36m2018\u001b[0m, cette année étant déjà très avancée, les contraintes de salle et de calendrier étant ce qu'elles sont, \n",
       "il n'a pas été possible de programmer ces cours suivant un rythme hebdomadaire régulier et c'est l'année prochaine \n",
       "seulement que nous aurons droit à un créneau fixe à compter du mois de janvier euh sachant toutefois que le \n",
       "séminaire public de l'année prochaine qui va doubler le cours donc commencera en fait dès la fin novembre.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#| eval: False\n",
    "print(transcript[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">us les enfants, les les personnes qui vivent ou les adultes qui vivent avec leurs parents. Et l'exploitation des \n",
       "données du recensement se fait dans le cadre du ménage, et pas seulement dans un cadre individuel. Et donc, chaque \n",
       "fois qu'un euh une personne, adulte ou enfant, vit encore avec ses parents, on a le le renseignement pour ses \n",
       "parents, euh on a les les les fameuses variables en question pour ses parents. Donc, il y aurait pas une rupture \n",
       "radicale à introduire ces questions, mais euh toute une série d'associations euh ou de syndicats sont opposés à \n",
       "cette introduction et parle de de recensement des origines, de fichage des origines, et cetera. Je rappelle que le \n",
       "recensement est anonyme, hein, et que il est évidemment étroitement surveillé, mais je je conçois très bien que \n",
       "tout ceci puisse se discuter. Voilà, et nous avons abordé déjà au cours de ce cours euh bien des bien des choses. \n",
       "Je vous remercie de votre formidable attention et je vous donne rendez-vous euh à lundi pour euh\n",
       "</pre>\n"
      ],
      "text/plain": [
       "us les enfants, les les personnes qui vivent ou les adultes qui vivent avec leurs parents. Et l'exploitation des \n",
       "données du recensement se fait dans le cadre du ménage, et pas seulement dans un cadre individuel. Et donc, chaque \n",
       "fois qu'un euh une personne, adulte ou enfant, vit encore avec ses parents, on a le le renseignement pour ses \n",
       "parents, euh on a les les les fameuses variables en question pour ses parents. Donc, il y aurait pas une rupture \n",
       "radicale à introduire ces questions, mais euh toute une série d'associations euh ou de syndicats sont opposés à \n",
       "cette introduction et parle de de recensement des origines, de fichage des origines, et cetera. Je rappelle que le \n",
       "recensement est anonyme, hein, et que il est évidemment étroitement surveillé, mais je je conçois très bien que \n",
       "tout ceci puisse se discuter. Voilà, et nous avons abordé déjà au cours de ce cours euh bien des bien des choses. \n",
       "Je vous remercie de votre formidable attention et je vous donne rendez-vous euh à lundi pour euh\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#| eval: False\n",
    "print(transcript[-1000:])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
